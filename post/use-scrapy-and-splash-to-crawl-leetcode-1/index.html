<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
  <title>使用Scrapy和Splash爬取LeetCode（1）：Scrapy框架入门 - ZintrulCre&#39;s Blog</title>
  <meta property="og:title" content="使用Scrapy和Splash爬取LeetCode（1）：Scrapy框架入门 - ZintrulCre&#39;s Blog" />
  <meta name="twitter:title" content="使用Scrapy和Splash爬取LeetCode（1）：Scrapy框架入门 - ZintrulCre&#39;s Blog" />
  <meta name="description" content="简介 Scrapy官方文档对Scrapy的介绍如下：
Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。
其最初是为了页面抓取（更确切来说, 网络抓取）所设计的，也可以应用在获取API所返回的数据（例如 Amazon Associates Web Services ）或者通用的网络爬虫。
简而言之，Scrapy是基于Twisted库开发的，封装了http请求、代理信息、数据存储等功能的Python爬虫框架。
组件和数据流 下图是Scrapy官方文档中的架构概览图：
图中绿色箭头表示数据流，其他均为组件。
Scrapy Engine（引擎） 引擎负责控制数据流在系统的组件中流动，并在相应动作发生时触发事件。
Scheduler（调度器） 调度器从引擎接收request并将其保存，以便在引擎请求时提供给引擎。
Downloader（下载器） 下载器负责下载页面数据，并将其提供给引擎，而后再由引擎提供给爬虫。
Spiders（爬虫） Spider是由用户编写的用于分析response并提取item或额外跟进url的类。一个Scrapy项目中可以有很多Spider，他们分别被用于爬取不同的页面和网站。
Item Pipeline（管道） Item Pipeline负责处理被爬虫提取出来的item。可以对其进行数据清洗，验证和持久化（例如存储到数据库中）。
Downloader middlewares（下载器中间件） 下载器中间件是在引擎及下载器之间的组件，用于处理下载器传递给引擎的response。更多内容请参考下载器中间件。
Spider middlewares（爬虫中间件） Spider中间件是在引擎及Spider之间的组件，用于处理爬虫的输入（response）和输出（items和requests）。更多内容请参考爬虫中间件。
Data flow（数据流） Scrapy中的数据流由引擎控制，其过程如下:
1.引擎打开一个网站，找到处理该网站的爬虫并向该爬虫请求要爬取的url。
2.引擎从爬虫中获取到要爬取的url并将其作为request发送给调度器。
3.引擎向调度器请求下一个要爬取的url。
4.调度器返回下一个要爬取的url给引擎，引擎将url通过下载器中间件发送给下载器。
5.下载器下载页面成功后，生成一个该页面的response对象，并将其通过下载器中间件发送给引擎。
6.引擎接收从下载器中间件发送过来的response，并将其通过爬虫中间件发送给爬虫处理。
7.爬虫处理response，并将爬取到的item及跟进的新的request发送给引擎。
8.引擎将爬虫返回的item发送给管道，将爬虫返回的新的request发送给调度器。
9.管道对item进行相应的处理。
10.重复第二步，直到调度器中没有更多的request，此时引擎关闭该网站。
安装 1.下载安装最新版的 Python3
2.使用pip指令安装Scrapy
 pip3 install scrapy  新建项目 首先进入你的代码存储目录，在命令行中输入以下命令：
scrapy startproject scrapy_project  startproject
新建成功后，可以看到在当前目录下新建了一个名为scrapy_project的Scrapy项目，其项目结构如下：
scrapy.cfg #该项目的配置文件 scrapy_project #该项目的Python模块 __init__.py items.py #可自定义的item类文件 middlewares.">
  <meta property="og:description" content="简介 Scrapy官方文档对Scrapy的介绍如下：
Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。
其最初是为了页面抓取（更确切来说, 网络抓取）所设计的，也可以应用在获取API所返回的数据（例如 Amazon Associates Web Services ）或者通用的网络爬虫。
简而言之，Scrapy是基于Twisted库开发的，封装了http请求、代理信息、数据存储等功能的Python爬虫框架。
组件和数据流 下图是Scrapy官方文档中的架构概览图：
图中绿色箭头表示数据流，其他均为组件。
Scrapy Engine（引擎） 引擎负责控制数据流在系统的组件中流动，并在相应动作发生时触发事件。
Scheduler（调度器） 调度器从引擎接收request并将其保存，以便在引擎请求时提供给引擎。
Downloader（下载器） 下载器负责下载页面数据，并将其提供给引擎，而后再由引擎提供给爬虫。
Spiders（爬虫） Spider是由用户编写的用于分析response并提取item或额外跟进url的类。一个Scrapy项目中可以有很多Spider，他们分别被用于爬取不同的页面和网站。
Item Pipeline（管道） Item Pipeline负责处理被爬虫提取出来的item。可以对其进行数据清洗，验证和持久化（例如存储到数据库中）。
Downloader middlewares（下载器中间件） 下载器中间件是在引擎及下载器之间的组件，用于处理下载器传递给引擎的response。更多内容请参考下载器中间件。
Spider middlewares（爬虫中间件） Spider中间件是在引擎及Spider之间的组件，用于处理爬虫的输入（response）和输出（items和requests）。更多内容请参考爬虫中间件。
Data flow（数据流） Scrapy中的数据流由引擎控制，其过程如下:
1.引擎打开一个网站，找到处理该网站的爬虫并向该爬虫请求要爬取的url。
2.引擎从爬虫中获取到要爬取的url并将其作为request发送给调度器。
3.引擎向调度器请求下一个要爬取的url。
4.调度器返回下一个要爬取的url给引擎，引擎将url通过下载器中间件发送给下载器。
5.下载器下载页面成功后，生成一个该页面的response对象，并将其通过下载器中间件发送给引擎。
6.引擎接收从下载器中间件发送过来的response，并将其通过爬虫中间件发送给爬虫处理。
7.爬虫处理response，并将爬取到的item及跟进的新的request发送给引擎。
8.引擎将爬虫返回的item发送给管道，将爬虫返回的新的request发送给调度器。
9.管道对item进行相应的处理。
10.重复第二步，直到调度器中没有更多的request，此时引擎关闭该网站。
安装 1.下载安装最新版的 Python3
2.使用pip指令安装Scrapy
 pip3 install scrapy  新建项目 首先进入你的代码存储目录，在命令行中输入以下命令：
scrapy startproject scrapy_project  startproject
新建成功后，可以看到在当前目录下新建了一个名为scrapy_project的Scrapy项目，其项目结构如下：
scrapy.cfg #该项目的配置文件 scrapy_project #该项目的Python模块 __init__.py items.py #可自定义的item类文件 middlewares.">
  <meta name="twitter:description" content="简介 Scrapy官方文档对Scrapy的介绍如下：
Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。
其最初是为了页面抓取（更确切来说, 网络抓取）所设计的，也可以应用在获取API所返回的数据（例如 Amazon Associates Web Services ）或者通用的网络爬虫。
简而言之，Scrapy是基 …">
  <meta name="author" content="Your name"/>
  <meta property="og:site_name" content="ZintrulCre&#39;s Blog" />
  <meta property="og:url" content="http://zintrulcre.top/post/use-scrapy-and-splash-to-crawl-leetcode-1/" />
  <meta property="og:type" content="article" />
  <meta name="twitter:card" content="summary" />
  <meta name="generator" content="Hugo 0.53" />

  <link rel="stylesheet" href="/css/style.css" media="all" />
  <link rel="stylesheet" href="/css/syntax.css" media="all" />
  <link rel="stylesheet" href="/css/custom.css" media="all" />

  <script src="/js/script.js"></script>
  <script src="/js/custom.js"></script>
  <script defer src="/js/fontawesome.js"></script>
</head>

<body>

<header class="site-header">
  <nav class="site-navi">
    <h1 class="site-title"><a href="/">ZintrulCre&#39;s Blog</a></h1>
    <ul class="site-navi-items">
      <li class="site-navi-item-categories"><a href="/categories/" title="Categories">Categories</a></li>
      <li class="site-navi-item-tags"><a href="/tags/" title="Tags">Tags</a></li>
      <li class="site-navi-item-archives"><a href="/archives/" title="Archives">Archives</a></li>
      <li class="site-navi-item-about"><a href="/about/" title="About">About</a></li>
    </ul>
  </nav>
</header>
<hr class="site-header-bottom">

  <div class="main" role="main">
    <article class="article">
      
      
      <h1 class="article-title">使用Scrapy和Splash爬取LeetCode（1）：Scrapy框架入门</h1>
      
      <hr class="article-title-bottom">
      <ul class="article-meta">
        <li class="article-meta-date"><time>January 3, 2019</time></li>
        <li class="article-meta-categories">
          <a href="/categories/spider/">
            <i class="fas fa-folder"></i>
            Spider
          </a>&nbsp;
        </li>
        <li class="article-meta-tags">
          <a href="/tags/spider/">
            <i class="fas fa-tag"></i>
            Spider
          </a>&nbsp;
        </li>
        <li class="article-meta-tags">
          <a href="/tags/scrapy/">
            <i class="fas fa-tag"></i>
            Scrapy
          </a>&nbsp;
        </li>
        <li class="article-meta-tags">
          <a href="/tags/splash/">
            <i class="fas fa-tag"></i>
            Splash
          </a>&nbsp;
        </li>
        <li class="article-meta-tags">
          <a href="/tags/leetcode/">
            <i class="fas fa-tag"></i>
            LeetCode
          </a>&nbsp;
        </li>
      </ul>
      
      

<h2 id="简介">简介</h2>

<p>Scrapy官方文档对Scrapy的介绍如下：</p>

<p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。<br>其最初是为了页面抓取（更确切来说, 网络抓取）所设计的，也可以应用在获取API所返回的数据（例如 Amazon Associates Web Services ）或者通用的网络爬虫。</p>

<p>简而言之，Scrapy是基于Twisted库开发的，封装了http请求、代理信息、数据存储等功能的Python爬虫框架。</p>

<h2 id="组件和数据流">组件和数据流</h2>

<p>下图是Scrapy官方文档中的架构概览图：</p>

<p><img src="https://scrapy-chs.readthedocs.io/zh_CN/0.24/_images/scrapy_architecture.png" alt="Architecture" /></p>

<p>图中绿色箭头表示<a href="#head">数据流</a>，其他均为组件。</p>

<h3 id="scrapy-engine-引擎">Scrapy Engine（引擎）</h3>

<p>引擎负责控制数据流在系统的组件中流动，并在相应动作发生时触发事件。</p>

<h3 id="scheduler-调度器">Scheduler（调度器）</h3>

<p>调度器从引擎接收request并将其保存，以便在引擎请求时提供给引擎。</p>

<h3 id="downloader-下载器">Downloader（下载器）</h3>

<p>下载器负责下载页面数据，并将其提供给引擎，而后再由引擎提供给爬虫。</p>

<h3 id="spiders-爬虫">Spiders（爬虫）</h3>

<p>Spider是由用户编写的用于<strong>分析response</strong>并<strong>提取item</strong>或额外<strong>跟进url</strong>的类。一个Scrapy项目中可以有很多Spider，他们分别被用于爬取不同的页面和网站。</p>

<h3 id="item-pipeline-管道">Item Pipeline（管道）</h3>

<p>Item Pipeline负责处理被爬虫<strong>提取出来的item</strong>。可以对其进行数据清洗，验证和持久化（例如存储到数据库中）。</p>

<h3 id="downloader-middlewares-下载器中间件">Downloader middlewares（下载器中间件）</h3>

<p>下载器中间件是在引擎及下载器之间的组件，用于处理下载器传递给引擎的response。更多内容请参考<a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/downloader-middleware.html#topics-downloader-middleware">下载器中间件</a>。</p>

<h3 id="spider-middlewares-爬虫中间件">Spider middlewares（爬虫中间件）</h3>

<p>Spider中间件是在引擎及Spider之间的组件，用于处理爬虫的输入（response）和输出（items和requests）。更多内容请参考<a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/topics/spider-middleware.html#topics-spider-middleware">爬虫中间件</a>。</p>

<h3 id="a-id-head-data-flow-数据流-a"><a id="head"/> Data flow（数据流）</a></h3>

<p>Scrapy中的数据流由引擎控制，其过程如下:<br>
1.引擎打开一个网站，找到处理该网站的爬虫并向该爬虫请求要爬取的url。<br>
2.引擎从爬虫中获取到要爬取的url并将其作为request发送给调度器。<br>
3.引擎向调度器请求下一个要爬取的url。<br>
4.调度器返回下一个要爬取的url给引擎，引擎将url通过下载器中间件发送给下载器。<br>
5.下载器下载页面成功后，生成一个该页面的response对象，并将其通过下载器中间件发送给引擎。<br>
6.引擎接收从下载器中间件发送过来的response，并将其通过爬虫中间件发送给爬虫处理。<br>
7.爬虫处理response，并将爬取到的item及跟进的新的request发送给引擎。<br>
8.引擎将爬虫返回的item发送给管道，将爬虫返回的新的request发送给调度器。<br>
9.管道对item进行相应的处理。<br>
10.重复第二步，直到调度器中没有更多的request，此时引擎关闭该网站。<br></p>

<h2 id="安装">安装</h2>

<p>1.下载安装最新版的 <a href="https://www.python.org/downloads/">Python3</a></p>

<p>2.使用pip指令安装Scrapy</p>

<pre><code>    pip3 install scrapy
</code></pre>

<h2 id="新建项目">新建项目</h2>

<p>首先进入你的代码存储目录，在命令行中输入以下命令：</p>

<pre><code>scrapy startproject scrapy_project
</code></pre>

<p>startproject</p>

<p>新建成功后，可以看到在当前目录下新建了一个名为scrapy_project的Scrapy项目，其项目结构如下：</p>

<pre><code>scrapy.cfg              #该项目的配置文件
scrapy_project          #该项目的Python模块
    __init__.py
    items.py            #可自定义的item类文件
    middlewares.py      #中间件文件
    pipelines.py        #管道文件
    settings.py         #设置文件
    __pycache__
    spiders             #爬虫文件夹，所有爬虫文件都应在该文件夹下
        __init__.py
        __pycache__
</code></pre>

<p>进入该项目文件夹，新建一个爬虫：</p>

<pre><code>cd scrapy_project
scrapy genspider leetcode_spider https://leetcode.com/
</code></pre>

<p>其中leetcode_spider是爬虫的名字，<a href="https://leetcode.com/">https://leetcode.com/</a> 是我们打算爬取的网站url。</p>

<p>至此Scrapy项目的新建就完成了。</p>

<h2 id="参考资料">参考资料</h2>

<p><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/" target="_blank">Scrapy官方文档</a></p>

    </article>

    
<ul class="article-share">
  <li>
    <a href="https://twitter.com/share" class="twitter-share-button">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </li>
  <li>
    <div class="fb-share-button" data-href="http://zintrulcre.top/post/use-scrapy-and-splash-to-crawl-leetcode-1/" data-layout="button_count" data-action="like" data-size="small" data-show-faces="true" data-share="true"></div>
    <div id="fb-root"></div>
    <script>(function(d, s, id) {
      var js, fjs = d.getElementsByTagName(s)[0];
      if (d.getElementById(id)) return;
      js = d.createElement(s); js.id = id;
      js.src = "//connect.facebook.net/ja_JP/sdk.js#xfbml=1&version=v2.10";
      fjs.parentNode.insertBefore(js, fjs);
    }(document, 'script', 'facebook-jssdk'));</script>
  </li>
  <li>
    <script src="https://apis.google.com/js/platform.js" async defer></script>
    <g:plus action="share"></g:plus>
  </li>
  <li>
    <a href="http://b.hatena.ne.jp/entry/" class="hatena-bookmark-button" data-hatena-bookmark-layout="basic-label-counter" data-hatena-bookmark-lang="en" title="このエントリーをはてなブックマークに追加"><img src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" alt="このエントリーをはてなブックマークに追加" width="20" height="20" style="border: none;" /></a><script src="https://b.st-hatena.com/js/bookmark_button.js" charset="utf-8" async="async"></script>
  </li>
  <li>
    <a data-pocket-label="pocket" data-pocket-count="horizontal" class="pocket-btn" data-lang="en"></a>
    <script>!function(d,i){if(!d.getElementById(i)){var j=d.createElement("script");j.id=i;j.src="https://widgets.getpocket.com/v1/j/btn.js?v=1";var w=d.getElementById(i);d.body.appendChild(j);}}(document,"pocket-btn-js");</script>
  </li>
</ul>

    <div class="disqus-comments">
      <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "Shortname" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>

    <ul class="pager article-pager">
      <li class="pager-newer pager-noitem">&lt; Newer</li>
      <li class="pager-older pager-noitem">Older &gt;</li>
    </ul>
  </div>


<div class="site-footer">
  <div class="copyright">&copy; Copyright 2019 ZintrulCre</div>
  <ul class="site-footer-items">
    <li class="site-footer-item-about"><a href="/about/" title="About">About</a></li>
  </ul>
  <div class="powerdby">
    Powered by <a href="https://gohugo.io/">Hugo</a> and <a href="https://github.com/taikii/whiteplain">Whiteplain</a>
  </div>
</div>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'Toracking ID', 'auto');
	
	ga('send', 'pageview');
}
</script>


</body>
</html>
