<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on ZinBlog</title>
    <link>http://zintrulcre.vip/categories/deep-learning/</link>
    <description>Recent content in Deep Learning on ZinBlog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Wed, 20 Mar 2019 09:55:04 +1100</lastBuildDate>
    
	<atom:link href="http://zintrulcre.vip/categories/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Methods to Prevent Overfitting in Deep Learning</title>
      <link>http://zintrulcre.vip/posts/deep-learning/methods-to-prevent-overfitting-in-deep-learning/</link>
      <pubDate>Wed, 20 Mar 2019 09:55:04 +1100</pubDate>
      
      <guid>http://zintrulcre.vip/posts/deep-learning/methods-to-prevent-overfitting-in-deep-learning/</guid>
      <description>Methods to Prevent Overfitting in Deep Learning Overfitting Overfitting refers to that when a model fits the training data well but cannot predict the test data correctly, we may say that the model lacks the ability of generalization. It is important to figure out how it happens, and how we can prevent overfitting from the very beginning.
Detect Overfitting The simplest way to detect overfitting is to split the dataset into two parts: the training set for training the model, and the test set for testing the accuracy of the model on a dataset that it has never seen before.</description>
    </item>
    
  </channel>
</rss>