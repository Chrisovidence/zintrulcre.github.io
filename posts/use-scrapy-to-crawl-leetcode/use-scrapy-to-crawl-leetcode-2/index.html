<!DOCTYPE html>
<html lang="en-us">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="author" content="Zhengyu Chen">
    <meta name="description" content="http://zintrulcre.vip">
    <meta name="keywords" content="ZintrulCre">
    
    <meta property="og:site_name" content="ZinBlog">
    <meta property="og:title" content="
  使用Scrapy爬取LeetCode（2）：爬取题目信息 - ZinBlog
">
    <meta property="og:description" content="">
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://zintrulcre.vip/posts/use-scrapy-to-crawl-leetcode/use-scrapy-to-crawl-leetcode-2/">
    <meta property="og:image" content="http://zintrulcre.vip">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="http://zintrulcre.vip/posts/use-scrapy-to-crawl-leetcode/use-scrapy-to-crawl-leetcode-2/">
    <meta name="twitter:image" content="http://zintrulcre.vip">

    <base href="http://zintrulcre.vip">
    <title>
  使用Scrapy爬取LeetCode（2）：爬取题目信息 - ZinBlog
</title>

    <link rel="canonical" href="http://zintrulcre.vip/posts/use-scrapy-to-crawl-leetcode/use-scrapy-to-crawl-leetcode-2/">
    
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.2.0/css/all.css" integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ" crossorigin="anonymous">
    
    <link  rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700">
    <link rel="stylesheet" href="//cdn.rawgit.com/necolas/normalize.css/master/normalize.css">
    <link rel="stylesheet" href="http://zintrulcre.vip/css/style.min.css">

    

    

    <link rel="icon" type="image/png" href="http://zintrulcre.vip/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="http://zintrulcre.vip/images/favicon-16x16.png" sizes="16x16">

    

    <meta name="generator" content="Hugo 0.53" />
  </head>

  <body class="">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">ZinBlog</a>
    <input type="checkbox" id="menu-control"/>
    <label class="menu-mobile  float-right " for="menu-control">
      <span class="btn-mobile  float-right ">&#9776;</span>
      <ul class="navigation-list">
        
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="http://zintrulcre.vip/posts/">Posts</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="http://zintrulcre.vip/categories/">Categories</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="http://zintrulcre.vip/notebooks/">Notebooks</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="http://zintrulcre.vip/projects/">Projects</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="http://zintrulcre.vip/bookmarks/">Bookmarks</a>
            </li>
          
            <li class="navigation-item  align-center ">
              <a class="navigation-link" href="http://zintrulcre.vip/about">About</a>
            </li>
          
        
        
      </ul>
    </label>
  </section>
</nav>


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/contrib/auto-render.min.js"></script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

      <div class="content">
        
  <section class="container post">
  <article>
    <header>
      <h1 class="title">使用Scrapy爬取LeetCode（2）：爬取题目信息</h1>
      <h2 class="date">December 21, 2018</h2>

      
    </header>

    

<p>本项目<a href="https://github.com/ZintrulCre/LeetCode_Crawler">ZintrulCre/LeetCode_Crawler</a>已完成，并正在维护中，欢迎在GitHub上star和fork。</p>

<h2 id="创建爬虫">创建爬虫</h2>

<p>在新建好项目后，用PyCharm或其他IDE打开该项目。进入该项目文件夹，使用<code>genspider</code>命令新建一个爬虫：</p>
<div class="highlight"><pre class="chroma">cd scrapy_project
scrapy genspider QuestionSetSpider leetcode.com</pre></div>
<p>其中QuestionSetSpider是爬虫的名字，leetcode.com是我们打算爬取的网站的域名。</p>

<p>新建好爬虫之后可以看到在项目的spiders文件夹下新增了一个名为 QuestionSetSpider.py的文件，这就是我们刚才新建的爬虫文件。这个爬虫文件会自动生成以下代码</p>
<div class="highlight"><pre class="chroma"># -*- coding: utf-8 -*-
import scrapy

class QuestionSetSpider(scrapy.Spider):
    name = &#39;QuestionSetSpider&#39;
    allowed_domains = [&#39;leetcode.com&#39;]
    start_urls = [&#39;http://leetcode.com/&#39;]

    def parse(self, response):
        pass</pre></div>
<ul>
<li>QuestionSetSpider类继承自scrapy.Spider，也就是scrapy框架中所有爬虫的基类；</li>
<li>self.name属性是该爬虫的名字，在该爬虫文件的外部可以通过这个属性获取当前爬虫；</li>
<li>self.allowed_domains是当前爬虫文件可以访问的域名列表，如果在爬取页面时进入了一个该域名以外的url会抛出错误；</li>
<li>self.start_urls是一个url列表，基类中定义了start_requests函数，它会遍历self.start_urls，并对每一个url调用scrapy.Request(url, dont_filter=True)，为了实现爬取题目的需求，我们需要重写self.start_urls函数</li>
</ul>

<h2 id="获取题目详细信息">获取题目详细信息</h2>

<h3 id="分析">分析</h3>

<p>LeetCode使用了GraphQL进行数据的查询和传输，大部分页面都是通过JS渲染生成的动态页面，所以无法直接从页面上获取标签，即使使用提供JavaScript渲染服务的库（例如Splash）也无法获取全部的数据，所以只能通过发送请求来获取数据。</p>

<p>为了爬取题目的详细信息，我们首先要从题目列表进入每个题目对应的链接。</p>

<p>首先打开leetcode的<a href="https://leetcode.com/problemset/all/">problem</a>列表，按F12打开Chrome的开发者工具，进入Network标签栏，勾选上Preserve log，刷新该页面。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/1.png" alt="1" /></p>

<p>可以看到，网页向 <a href="https://leetcode.com/api/problems/all/">https://leetcode.com/api/problems/all/</a> 发送了一个名为&rdquo;all/&ldquo;的GET类型的Request，这就是获取所有题目链接和相关信息的请求。如果此时已经安装了Toggle JavaScript插件，我们可以直接右键点击“Open in new tab”，查看该请求返回的Response。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/2.png" alt="2" /></p>

<p>更方便的方法是使用postman向服务器发送一个相同的Request，并将其保存下来，这样如果我们下次需要查看相应的Response的时候就不需要再使用开发者工具了。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/3.png" alt="3" /></p>

<p>返回的Response是一个json对象，其中的&rdquo;stat_status_pairs&rdquo;键所对应的值是所有包含题目信息的list，而列表中的[&ldquo;stat&rdquo;][&ldquo;question__title_slug&rdquo;]就是题目所在的页面。以Largest Perimeter Triangle为例，将其title_slug拼接到<a href="https://leetcode.com/problems/">https://leetcode.com/problems/</a> 后，进入页面<a href="https://leetcode.com/problems/largest-perimeter-triangle/">https://leetcode.com/problems/largest-perimeter-triangle/</a> 。同样地，打开开发者工具，刷新页面，可以看到服务器返回了很多项graphql的查询数据，通过查看Request Payload可以找到其中operationName为&rdquo;questionData&rdquo;的一项，这就是当前题目的详细信息。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/4.png" alt="4" /></p>

<p>将Payload复制粘贴到postman的Body中，在Headers中设置Content-Type为application/json，发送请求，可以看到返回的是一个json对象，包含了该题目所对应的所有信息。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/5.png" alt="5" /></p>

<p>接下来我们就可以对该题目的信息进行处理了。</p>

<h3 id="实现">实现</h3>

<p>为了获取题目列表的json对象，我们需要先重写start_requests函数。</p>
<div class="highlight"><pre class="chroma">def start_requests(self):
        self.Login() # 用户登录，后续会用到
        questionset_url = &#34;https://leetcode.com/api/problems/all/&#34;
        yield scrapy.Request(url=questionset_url, callback=self.ParseQuestionSet)</pre></div>
<p>Request是scrapy的一个类对象，功能类似于requests库中的get函数，可以让scrapy框架中的Downloader向url发送一个get请求，并将获取的response交给指定的爬虫文件中的回调函数进行相应的处理，其构造函数如下</p>
<div class="highlight"><pre class="chroma">class Request(object_ref):

    def __init__(self, url, callback=None, method=&#39;GET&#39;, headers=None, body=None, cookies=None, meta=None, encoding=&#39;utf-8&#39;, priority=0, dont_filter=False, errback=None, flags=None):
    ...</pre></div>
<p>在获取到json对象之后，可以通过遍历&rdquo;stat_status_pairs&rdquo;键所对应的列表，并取出[&ldquo;stat&rdquo;][&ldquo;question__title_slug&rdquo;]的值，得到题目的title_slug。此时我们不再需要进行打开题目相关页面的操作，直接向GraphQL发送查询详细信息的request即可。</p>

<p>我们可以从postman直接获取到发送请求相关的代码。因为每个题目的title_slug不同，我们可以将Payload中titleSlug后的字段改为一个不会重复的独特的字符串，在每一次获取到新的title_slug之后用replace函数替换它，发送新的请求，然后再将其替换回独特的字符串。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/6.png" alt="6" /></p>

<p>准备好Payload和Headers之后，我们可以使用FormRequest发送POST请求向GraphQL查询数据。FormRequest是scrapy的一个类对象，功能类似于requests库中的post函数，让scrapy框架中的Downloader向url发送一个post请求，并将获取的response交给指定的爬虫文件中的回调函数进行相应的处理。此处在发送POST请求之后response被交给ParseQuestionData函数进行处理。</p>
<div class="highlight"><pre class="chroma">    question_payload = &#34;{\n    \&#34;operationName\&#34;: \&#34;questionData\&#34;,\n    \&#34;variables\&#34;: {\n        \&#34;titleSlug\&#34;: \&#34;QuestionName\&#34;\n    },\n    \&#34;query\&#34;: \&#34;query questionData($titleSlug: String!) {\\n  question(titleSlug: $titleSlug) {\\n    questionId\\n    questionFrontendId\\n    boundTopicId\\n    title\\n    titleSlug\\n    content\\n    translatedTitle\\n    translatedContent\\n    isPaidOnly\\n    difficulty\\n    likes\\n    dislikes\\n    isLiked\\n    similarQuestions\\n    contributors {\\n      username\\n      profileUrl\\n      avatarUrl\\n      __typename\\n    }\\n    langToValidPlayground\\n    topicTags {\\n      name\\n      slug\\n      translatedName\\n      __typename\\n    }\\n    companyTagStats\\n    codeSnippets {\\n      lang\\n      langSlug\\n      code\\n      __typename\\n    }\\n    stats\\n    hints\\n    solution {\\n      id\\n      canSeeDetail\\n      __typename\\n    }\\n    status\\n    sampleTestCase\\n    metaData\\n    judgerAvailable\\n    judgeType\\n    mysqlSchemas\\n    enableRunCode\\n    enableTestMode\\n    envInfo\\n    __typename\\n  }\\n}\\n\&#34;\n}\n&#34;

    graphql_url = &#34;https://leetcode.com/graphql&#34;

    def ParseQuestionSet(self, response):
        headers = {
            &#34;user_agent&#34;: &#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36&#39;&#34;,
            &#34;content-type&#34;: &#34;application/json&#34;  # necessary
        }
        questionSet = json.loads(response.text)
        questionSet = questionSet[&#34;stat_status_pairs&#34;]
        for question in questionSet:
            title_slug = question[&#34;stat&#34;][&#34;question__title_slug&#34;]
            self.question_payload = self.question_payload.replace(&#34;QuestionName&#34;, title_slug)
            yield scrapy.FormRequest(url=self.graphql_url, callback=self.ParseQuestionData,
                                     headers=headers, body=self.question_payload)
            self.question_payload = self.question_payload.replace(title_slug, &#34;QuestionName&#34;)</pre></div>
<p>现在数据已经获取到了，我们需要在items.py文件中定义一个类用来存储题目的详细信息。items.py文件中的类继承自scrapy.Item类，是提供给scrapy框架中的组件Item Pipeline进行处理的统一的的数据结构。</p>
<div class="highlight"><pre class="chroma">import scrapy

class QuestionDataItem(scrapy.Item):
    # define the fields for your item here like:
    # name = scrapy.Field()
    id = scrapy.Field()
    title = scrapy.Field()
    content = scrapy.Field()
    submission_list = scrapy.Field()
    topics = scrapy.Field()
    difficulty = scrapy.Field()
    ac_rate = scrapy.Field()
    likes = scrapy.Field()
    dislikes = scrapy.Field()
    slug = scrapy.Field()</pre></div>
<p>定义了QuestionDataItem类之后可以进入ParseQuestionData函数开始对题目详细信息的提取，我们可以根据需求提取出题目的id，title，content，topics，difficulty等信息，用一个QuestionDataItem对象来存储这些数据，然后进行yield questionDataItem操作，将这个对象交给Item Pipeline进行处理。</p>
<div class="highlight"><pre class="chroma">    def ParseQuestionData(self, response):
        questionData = json.loads(response.text)[&#34;data&#34;][&#34;question&#34;]
        questionDataItem = QuestionDataItem()
        questionDataItem[&#34;id&#34;] = questionData[&#34;questionFrontendId&#34;]
        questionDataItem[&#34;title&#34;] = questionData[&#34;title&#34;]
        questionDataItem[&#34;content&#34;] = questionData[&#34;content&#34;]
        topics = []
        for topic in questionData[&#34;topicTags&#34;]:
            topics.append(topic[&#34;name&#34;])
        if len(topics) == 0:
            topics.append(&#34;None&#34;)
        questionDataItem[&#34;topics&#34;] = topics
        questionDataItem[&#34;difficulty&#34;] = questionData[&#34;difficulty&#34;]
        stats = json.loads(questionData[&#34;stats&#34;])
        questionDataItem[&#34;ac_rate&#34;] = stats[&#34;acRate&#34;]
        questionDataItem[&#34;likes&#34;] = questionData[&#34;likes&#34;]
        questionDataItem[&#34;dislikes&#34;] = questionData[&#34;dislikes&#34;]
        questionDataItem[&#34;slug&#34;] = questionData[&#34;titleSlug&#34;]
        submission_list = self.GetSubmissionList(questionDataItem[&#34;slug&#34;])
        questionDataItem[&#34;submission_list&#34;] = submission_list

        yield questionDataItem</pre></div>
<p>至此题目信息的爬取就完成了。</p>

<h2 id="参考资料">参考资料</h2>

<p><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/" target="_blank">Scrapy官方文档</a></p>

<p><a href="https://learning.getpostman.com/docs/postman/launching_postman/installation_and_updates/">Postman官方文档</a></p>

  </article>

  <br/>

  
      <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "zintrulcre" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
  
  
</section>

      </div>
      
        
<script>renderMathInElement(document.body);</script>
      
    </main>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-132809676-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


  <script src="http://zintrulcre.vip/js/app.js"></script>
  
  </body>
</html>
