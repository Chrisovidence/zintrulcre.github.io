<!DOCTYPE html>
<html lang="en-us">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="X-UA-Compatible" content="ie=edge">
	<meta name="theme-color" content="#494f5c">
	<meta name="msapplication-TileColor" content="#494f5c">
<meta itemprop="name" content="使用Scrapy爬取LeetCode（2）：爬取题目信息">
<meta itemprop="description" content="创建爬虫 在新建好项目后，用PyCharm或其他IDE打开该项目。进入该项目文件夹，使用genspider命令新建一个爬虫： cd scrapy_project scrapy genspider QuestionSetSpider leetcode.com 其中Q">


<meta itemprop="datePublished" content="2019-01-18T15:06:01&#43;11:00" />
<meta itemprop="dateModified" content="2019-01-18T15:06:01&#43;11:00" />
<meta itemprop="wordCount" content="2880">



<meta itemprop="keywords" content="Python,Scrapy,LeetCode,爬虫," />
<meta property="og:title" content="使用Scrapy爬取LeetCode（2）：爬取题目信息" />
<meta property="og:description" content="创建爬虫 在新建好项目后，用PyCharm或其他IDE打开该项目。进入该项目文件夹，使用genspider命令新建一个爬虫： cd scrapy_project scrapy genspider QuestionSetSpider leetcode.com 其中Q" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://zintrulcre.vip/posts/use-scrapy-to-crawl-leetcode-2/" /><meta property="article:published_time" content="2019-01-18T15:06:01&#43;11:00"/>
<meta property="article:modified_time" content="2019-01-18T15:06:01&#43;11:00"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="使用Scrapy爬取LeetCode（2）：爬取题目信息"/>
<meta name="twitter:description" content="创建爬虫 在新建好项目后，用PyCharm或其他IDE打开该项目。进入该项目文件夹，使用genspider命令新建一个爬虫： cd scrapy_project scrapy genspider QuestionSetSpider leetcode.com 其中Q"/>
	<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">
	<link rel="mask-icon" href="/safari-pinned-tab.svg" color="">
	<link rel="shortcut icon" href="/favicon.ico">

	<title>使用Scrapy爬取LeetCode（2）：爬取题目信息</title>
	<link rel="stylesheet" href="http://zintrulcre.vip/css/style.min.9a30741782203507f3d35fe9cefabad487c72fc82dfbdf59121759fc2fa52f92.css" integrity="sha256-mjB0F4IgNQfz01/pzvq61IfHL8gt+99ZEhdZ/C+lL5I=">
	
</head>

<body id="page">
	
	<header id="site-header" class="animated slideInUp faster">
		<div class="hdr-wrapper section-inner">
			<div class="hdr-left">
				<div class="site-branding">
					<a href="http://zintrulcre.vip">ZintrulCre</a>
				</div>
				<nav class="site-nav hide-in-mobile">
					<a href="http://zintrulcre.vip/posts/">Posts</a>
					<a href="http://zintrulcre.vip/about-hugo/">About</a>
				</nav>
			</div>
			<div class="hdr-right hdr-icons">
				<span class="hdr-social hide-in-mobile"><a href="https://github.com/ZintrulCre" target="_blank" rel="noopener" title="Github"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg></a><a href="https://twitter.com/ZintrulCre" target="_blank" rel="noopener" title="Twitter"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-twitter"><path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path></svg></a><a href="https://www.linkedin.com/in/%E6%AD%A3%E5%AE%87-%E9%99%88-19065a164/" target="_blank" rel="noopener" title="Linkedin"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-linkedin"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle></svg></a><a href="https://www.youtube.com/channel/UC3y5yK_ms60X90fVKbTpYeg?view_as=subscriber" target="_blank" rel="noopener" title="Youtube"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-youtube"><path d="M22.54 6.42a2.78 2.78 0 0 0-1.94-2C18.88 4 12 4 12 4s-6.88 0-8.6.46a2.78 2.78 0 0 0-1.94 2A29 29 0 0 0 1 11.75a29 29 0 0 0 .46 5.33A2.78 2.78 0 0 0 3.4 19c1.72.46 8.6.46 8.6.46s6.88 0 8.6-.46a2.78 2.78 0 0 0 1.94-2 29 29 0 0 0 .46-5.25 29 29 0 0 0-.46-5.33z"></path><polygon points="9.75 15.02 15.5 11.75 9.75 8.48 9.75 15.02"></polygon></svg></a></span><button id="menu-btn" class="hdr-btn" title="Menu"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></button>
			</div>
		</div>
	</header>
	<div id="mobile-menu" class="animated fast">
		<ul>
			<li><a href="http://zintrulcre.vip/posts/">Posts</a></li>
			<li><a href="http://zintrulcre.vip/about-hugo/">About</a></li>
		</ul>
	</div>


	<main class="site-main section-inner animated fadeIn faster">
		<article class="thin">
			<header class="post-header">
				<div class="post-meta"><span>Jan 18, 2019</span></div>
				<h1>使用Scrapy爬取LeetCode（2）：爬取题目信息</h1>
			</header>
			<div class="content">
				

<h2 id="创建爬虫">创建爬虫</h2>

<p>在新建好项目后，用PyCharm或其他IDE打开该项目。进入该项目文件夹，使用<code>genspider</code>命令新建一个爬虫：</p>

<pre><code>cd scrapy_project
scrapy genspider QuestionSetSpider leetcode.com
</code></pre>

<p>其中QuestionSetSpider是爬虫的名字，leetcode.com是我们打算爬取的网站的域名。</p>

<p>新建好爬虫之后可以看到在项目的spiders文件夹下新增了一个名为 QuestionSetSpider.py的文件，这就是我们刚才新建的爬虫文件。这个爬虫文件会自动生成以下代码</p>

<pre><code># -*- coding: utf-8 -*-
import scrapy

class QuestionSetSpider(scrapy.Spider):
    name = 'QuestionSetSpider'
    allowed_domains = ['leetcode.com']
    start_urls = ['http://leetcode.com/']

    def parse(self, response):
        pass

</code></pre>

<ul>
<li>QuestionSetSpider类继承自scrapy.Spider，也就是scrapy框架中所有爬虫的基类；</li>
<li>self.name属性是该爬虫的名字，在该爬虫文件的外部可以通过这个属性获取当前爬虫；</li>
<li>self.allowed_domains是当前爬虫文件可以访问的域名列表，如果在爬取页面时进入了一个该域名以外的url会抛出错误；</li>
<li>self.start_urls是一个url列表，基类中定义了start_requests函数，它会遍历self.start_urls，并对每一个url调用scrapy.Request(url, dont_filter=True)，为了实现爬取题目的需求，我们需要重写self.start_urls函数</li>
</ul>

<h2 id="获取题目详细信息">获取题目详细信息</h2>

<h3 id="分析">分析</h3>

<p>LeetCode使用了GraphQL进行数据的查询和传输，大部分页面都是通过JS渲染生成的动态页面，所以无法直接从页面上获取标签，即使使用提供JavaScript渲染服务的库（例如Splash）也无法获取全部的数据，所以只能通过发送请求来获取数据。</p>

<p>为了爬取题目的详细信息，我们首先要从题目列表进入每个题目对应的链接。</p>

<p>首先打开leetcode的<a href="https://leetcode.com/problemset/all/" target="_blank">problem</a>列表，按F12打开Chrome的开发者工具，进入Network标签栏，勾选上Preserve log，刷新该页面。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/1.png" alt="1" /></p>

<p>可以看到，网页向 <a href="https://leetcode.com/api/problems/all/" target="_blank">https://leetcode.com/api/problems/all/</a> 发送了一个名为&rdquo;all/&ldquo;的GET类型的Request，这就是获取所有题目链接和相关信息的请求。如果此时已经安装了Toggle JavaScript插件，我们可以直接右键点击“Open in new tab”，查看该请求返回的Response。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/2.png" alt="2" /></p>

<p>更方便的方法是使用postman向服务器发送一个相同的Request，并将其保存下来，这样如果我们下次需要查看相应的Response的时候就不需要再使用开发者工具了。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/3.png" alt="3" /></p>

<p>返回的Response是一个json对象，其中的&rdquo;stat_status_pairs&rdquo;键所对应的值是所有包含题目信息的list，而列表中的[&ldquo;stat&rdquo;][&ldquo;question__title_slug&rdquo;]就是题目所在的页面。以Largest Perimeter Triangle为例，将其title_slug拼接到<a href="https://leetcode.com/problems/" target="_blank">https://leetcode.com/problems/</a> 后，进入页面<a href="https://leetcode.com/problems/largest-perimeter-triangle/。同样地，打开开发者工具，刷新页面，可以看到服务器返回了很多项graphql的查询数据，通过查看Request" target="_blank">https://leetcode.com/problems/largest-perimeter-triangle/。同样地，打开开发者工具，刷新页面，可以看到服务器返回了很多项graphql的查询数据，通过查看Request</a> Payload可以找到其中operationName为&rdquo;questionData&rdquo;的一项，这就是当前题目的详细信息。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/4.png" alt="4" /></p>

<p>将Payload复制粘贴到postman的Body中，在Headers中设置Content-Type为application/json，发送请求，可以看到返回的是一个json对象，包含了该题目所对应的所有信息。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/5.png" alt="5" /></p>

<p>接下来我们就可以对该题目的信息进行处理了。</p>

<h3 id="实现">实现</h3>

<p>为了获取题目列表的json对象，我们需要先重写start_requests函数。</p>

<pre><code>def start_requests(self):
        self.Login() # 用户登录，后续会用到
        questionset_url = &quot;https://leetcode.com/api/problems/all/&quot;
        yield scrapy.Request(url=questionset_url, callback=self.ParseQuestionSet)
</code></pre>

<p>Request是scrapy的一个类对象，功能类似于requests库中的get函数，可以让scrapy框架中的Downloader向url发送一个get请求，并将获取的response交给指定的爬虫文件中的回调函数进行相应的处理，其构造函数如下</p>

<pre><code>class Request(object_ref):

    def __init__(self, url, callback=None, method='GET', headers=None, body=None, cookies=None, meta=None, encoding='utf-8', priority=0, dont_filter=False, errback=None, flags=None):
    ...
</code></pre>

<p>在获取到json对象之后，可以通过遍历&rdquo;stat_status_pairs&rdquo;键所对应的列表，并取出[&ldquo;stat&rdquo;][&ldquo;question__title_slug&rdquo;]的值，得到题目的title_slug。此时我们不再需要进行打开题目相关页面的操作，直接向GraphQL发送查询详细信息的request即可。</p>

<p>我们可以从postman直接获取到发送请求相关的代码。因为每个题目的title_slug不同，我们可以将Payload中titleSlug后的字段改为一个不会重复的独特的字符串，在每一次获取到新的title_slug之后用replace函数替换它，发送新的请求，然后再将其替换回独特的字符串。</p>

<p><img src="https://raw.githubusercontent.com/ZintrulCre/zintrulcre.github.io/master/data/Use-Scrapy-to-Crawl-LeetCode/6.png" alt="6" /></p>

<p>准备好Payload和Headers之后，我们可以使用FormRequest发送POST请求向GraphQL查询数据。FormRequest是scrapy的一个类对象，功能类似于requests库中的post函数，让scrapy框架中的Downloader向url发送一个post请求，并将获取的response交给指定的爬虫文件中的回调函数进行相应的处理。此处在发送POST请求之后response被交给ParseQuestionData函数进行处理。</p>

<pre><code>    question_payload = &quot;{\n    \&quot;operationName\&quot;: \&quot;questionData\&quot;,\n    \&quot;variables\&quot;: {\n        \&quot;titleSlug\&quot;: \&quot;QuestionName\&quot;\n    },\n    \&quot;query\&quot;: \&quot;query questionData($titleSlug: String!) {\\n  question(titleSlug: $titleSlug) {\\n    questionId\\n    questionFrontendId\\n    boundTopicId\\n    title\\n    titleSlug\\n    content\\n    translatedTitle\\n    translatedContent\\n    isPaidOnly\\n    difficulty\\n    likes\\n    dislikes\\n    isLiked\\n    similarQuestions\\n    contributors {\\n      username\\n      profileUrl\\n      avatarUrl\\n      __typename\\n    }\\n    langToValidPlayground\\n    topicTags {\\n      name\\n      slug\\n      translatedName\\n      __typename\\n    }\\n    companyTagStats\\n    codeSnippets {\\n      lang\\n      langSlug\\n      code\\n      __typename\\n    }\\n    stats\\n    hints\\n    solution {\\n      id\\n      canSeeDetail\\n      __typename\\n    }\\n    status\\n    sampleTestCase\\n    metaData\\n    judgerAvailable\\n    judgeType\\n    mysqlSchemas\\n    enableRunCode\\n    enableTestMode\\n    envInfo\\n    __typename\\n  }\\n}\\n\&quot;\n}\n&quot;

    graphql_url = &quot;https://leetcode.com/graphql&quot;

    def ParseQuestionSet(self, response):
        headers = {
            &quot;user_agent&quot;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'&quot;,
            &quot;content-type&quot;: &quot;application/json&quot;  # necessary
        }
        questionSet = json.loads(response.text)
        questionSet = questionSet[&quot;stat_status_pairs&quot;]
        for question in questionSet:
            title_slug = question[&quot;stat&quot;][&quot;question__title_slug&quot;]
            self.question_payload = self.question_payload.replace(&quot;QuestionName&quot;, title_slug)
            yield scrapy.FormRequest(url=self.graphql_url, callback=self.ParseQuestionData,
                                     headers=headers, body=self.question_payload)
            self.question_payload = self.question_payload.replace(title_slug, &quot;QuestionName&quot;)
</code></pre>

<p>现在数据已经获取到了，我们需要在items.py文件中定义一个类用来存储题目的详细信息。items.py文件中的类继承自scrapy.Item类，是提供给scrapy框架中的组件Item Pipeline进行处理的统一的的数据结构。</p>

<pre><code>import scrapy

class QuestionDataItem(scrapy.Item):
    # define the fields for your item here like:
    # name = scrapy.Field()
    id = scrapy.Field()
    title = scrapy.Field()
    content = scrapy.Field()
    submission_list = scrapy.Field()
    topics = scrapy.Field()
    difficulty = scrapy.Field()
    ac_rate = scrapy.Field()
    likes = scrapy.Field()
    dislikes = scrapy.Field()
    slug = scrapy.Field()
</code></pre>

<p>定义了QuestionDataItem类之后可以进入ParseQuestionData函数开始对题目详细信息的提取，我们可以根据需求提取出题目的id，title，content，topics，difficulty等信息，用一个QuestionDataItem对象来存储这些数据，然后进行yield questionDataItem操作，将这个对象交给Item Pipeline进行处理。</p>

<pre><code>    def ParseQuestionData(self, response):
        questionData = json.loads(response.text)[&quot;data&quot;][&quot;question&quot;]
        questionDataItem = QuestionDataItem()
        questionDataItem[&quot;id&quot;] = questionData[&quot;questionFrontendId&quot;]
        questionDataItem[&quot;title&quot;] = questionData[&quot;title&quot;]
        questionDataItem[&quot;content&quot;] = questionData[&quot;content&quot;]
        topics = []
        for topic in questionData[&quot;topicTags&quot;]:
            topics.append(topic[&quot;name&quot;])
        if len(topics) == 0:
            topics.append(&quot;None&quot;)
        questionDataItem[&quot;topics&quot;] = topics
        questionDataItem[&quot;difficulty&quot;] = questionData[&quot;difficulty&quot;]
        stats = json.loads(questionData[&quot;stats&quot;])
        questionDataItem[&quot;ac_rate&quot;] = stats[&quot;acRate&quot;]
        questionDataItem[&quot;likes&quot;] = questionData[&quot;likes&quot;]
        questionDataItem[&quot;dislikes&quot;] = questionData[&quot;dislikes&quot;]
        questionDataItem[&quot;slug&quot;] = questionData[&quot;titleSlug&quot;]
        submission_list = self.GetSubmissionList(questionDataItem[&quot;slug&quot;])
        questionDataItem[&quot;submission_list&quot;] = submission_list

        yield questionDataItem
</code></pre>

<p>至此题目信息的爬取就完成了。</p>

<h2 id="参考资料">参考资料</h2>

<p><a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/" target="_blank">Scrapy官方文档</a></p>

<p><a href="https://www.getpostman.com/">Postman</a></p>

			</div>
			<hr class="post-end">
			<footer class="post-info">
				<p>
					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="http://zintrulcre.vip/tags/python">Python</a></span><span class="tag"><a href="http://zintrulcre.vip/tags/scrapy">Scrapy</a></span><span class="tag"><a href="http://zintrulcre.vip/tags/leetcode">LeetCode</a></span><span class="tag"><a href="http://zintrulcre.vip/tags/%E7%88%AC%E8%99%AB">爬虫</a></span>
				</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>2880 Words</p>
				<p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>2019-01-18 15:06</p>
			</footer>
		</article>
		<div class="post-nav thin">
			<a class="prev-post" href="http://zintrulcre.vip/posts/run-jupyter-notebook-on-gcp/">
				<span class="post-nav-label">Older&nbsp;<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-arrow-right"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg></span><br><span>在Google Cloud Platform上运行Jupyter Notebook</span>
			</a>
		</div>
		<div id="comments" class="thin">
<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "zintrulcre" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
	</main>

	<footer id="site-footer" class="section-inner thin animated fadeIn faster">
		<p>&copy; 2019 <a href="http://zintrulcre.vip">Zhengyu Chen</a></p>
		<p>
			Made with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> &#183; Theme <a href="https://github.com/Track3/hermit" target="_blank" rel="noopener">Hermit</a> &#183; <a href="http://zintrulcre.vip/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a>
		</p>
	</footer>


	<script src="http://zintrulcre.vip/js/main.min.8f39f24808e9d0a9b02da58c2d2838da859dc0b7bdfadbdb1883aae8b6adacfe.js" integrity="sha256-jznySAjp0KmwLaWMLSg42oWdwLe9+tvbGIOq6LatrP4="></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-132809676-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


</body>

</html>
